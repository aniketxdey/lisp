{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ctc_loss_imp import ctc_loss_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.0246, grad_fn=<MeanBackward0>)\n",
      "tensor(10.0246, grad_fn=<MeanBackward0>) tensor(10.0246, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device    = 'cpu'\n",
    "T  = 40\n",
    "C_SIZE = 5\n",
    "\n",
    "tgt_len = [5,5,5,5]\n",
    "inp_len = [T,T,T,T]\n",
    "BS = len(tgt_len)\n",
    "\n",
    "targets = torch.randint(BS, C_SIZE , (sum(tgt_len),), dtype=torch.int)\n",
    "log_probs = torch.nn.Parameter((torch.randn(T, BS, C_SIZE, dtype=torch.float, device=device).softmax(2))).log()\n",
    "\n",
    "ctc_loss = torch.nn.CTCLoss()\n",
    "ctc_loss_custom = ctc_loss_imp_log_space_2\n",
    "out_built_in = ctc_loss(log_probs, targets, inp_len, tgt_len) # in log space\n",
    "out_custom = ctc_loss_custom(log_probs, targets, inp_len, tgt_len)  # in soft max space\n",
    "\n",
    "print(out_built_in, out_custom)\n",
    "assert torch.norm(out_built_in - out_custom) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neginf    = torch.tensor(-float('inf'))\n",
    "def ctc_loss_imp_log_space_2(inp, targets, inp_len, tgt_len, BLANK=0, reduction='mean'):\n",
    "        # inp in log space\n",
    "        inp_len       = torch.as_tensor(inp_len, dtype=torch.int)\n",
    "        tgt_len       = torch.as_tensor(tgt_len, dtype=torch.int)\n",
    "        cum_tgt_len   = tgt_len.cumsum(0)\n",
    "        losses        = []\n",
    "        alpha_global  = []\n",
    "\n",
    "        for i in range(inp.size(1)):\n",
    "            inp_length          = inp_len[i].item()\n",
    "            target_length       = tgt_len[i].item()\n",
    "            cum_target_length   = cum_tgt_len[i].item()\n",
    "\n",
    "            targets_prime = targets.new_full((2 * target_length + 1,), BLANK)\n",
    "            if targets.dim() == 2:\n",
    "                targets_prime[1::2] = targets[i, :target_length]\n",
    "            else:\n",
    "                targets_prime[1::2] = targets[cum_target_length - target_length:cum_target_length]\n",
    "\n",
    "            probs = inp[:inp_length, i]\n",
    "            alpha   = inp.new_ones((inp_length, target_length*2+1)) * neginf \n",
    "            alpha[0,0] = probs[0, BLANK]\n",
    "            if target_length > 0:\n",
    "                alpha[0,1] = probs[0, targets_prime[1]]\n",
    "\n",
    "            for t in range(1, inp_length):\n",
    "                for s in range(2 * target_length +1):\n",
    "                    a1 = alpha[t-1,s]\n",
    "                    a2 = alpha[t-1,s-1] if s > 0 else neginf\n",
    "                    a3 = alpha[t-1,s-2] if s > 1 and targets_prime[s-2]!= targets_prime[s] else neginf\n",
    "\n",
    "                    amax = max(a1,a2,a3)\n",
    "                    amax = 0 if amax == neginf else amax\n",
    "                    \n",
    "                    alpha[t,s] = torch.log( torch.exp(a1-amax) + torch.exp(a2-amax) + torch.exp(a3-amax)) + \\\n",
    "                        amax + probs[t, targets_prime[s]]\n",
    "\n",
    "            if target_length == 0:\n",
    "                loss = -alpha[-1,0]\n",
    "            else:\n",
    "                l1 = alpha[-1,-2]\n",
    "                l2 = alpha[-1,-1]\n",
    "                loss = -torch.log(torch.exp(l1)+ torch.exp(l2))\n",
    "            losses.append(loss[None])\n",
    "            alpha_global.append(alpha)\n",
    "        output = torch.cat(losses, 0)\n",
    "        if reduction == 'mean':\n",
    "            print( (output / tgt_len.to(dtype=output.dtype, device=output.device)).mean() )\n",
    "        elif reduction == 'sum':\n",
    "            print( output.sum() )\n",
    "\n",
    "        output_mean = (output / tgt_len.to(dtype=output.dtype, device=output.device)).mean()\n",
    "\n",
    "        return output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(inf, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_imp = ctc_loss_imp_log_space_2(input, target, input_lengths, target_lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr_reveal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
